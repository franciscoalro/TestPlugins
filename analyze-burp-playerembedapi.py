#!/usr/bin/env python3
"""
Analisa arquivo JSON do Burp Suite para encontrar URLs de v√≠deo do PlayerEmbedAPI
"""

import json
import base64
import re
from urllib.parse import unquote

def decode_base64(encoded):
    """Decodifica string base64"""
    try:
        return base64.b64decode(encoded).decode('utf-8', errors='ignore')
    except:
        return ""

def extract_video_urls(text):
    """Extrai URLs de v√≠deo do texto"""
    patterns = [
        r'https?://[^\s"\'<>]+\.mp4[^\s"\'<>]*',
        r'https?://[^\s"\'<>]+\.m3u8[^\s"\'<>]*',
        r'https?://storage\.googleapis\.com[^\s"\'<>]+',
        r'https?://[^\s"\'<>]*cloudatacdn[^\s"\'<>]+',
        r'https?://[^\s"\'<>]*iamcdn[^\s"\'<>]+',
        r'https?://[^\s"\'<>]*sssrr[^\s"\'<>]+',
    ]
    
    urls = set()
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        urls.update(matches)
    
    return urls

def analyze_burp_json(file_path, max_requests=100):
    """Analisa arquivo JSON do Burp Suite"""
    print(f"üîç Analisando: {file_path}")
    print(f"‚ö†Ô∏è  Limitando a {max_requests} requisi√ß√µes (arquivo muito grande)")
    print()
    
    video_urls = set()
    playerembedapi_requests = []
    
    # Ler arquivo linha por linha (JSON array)
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read(10_000_000)  # Ler primeiros 10MB
        
        # Tentar parsear como JSON
        try:
            # Encontrar todas as requisi√ß√µes playerembedapi
            matches = re.finditer(r'\{"id":\d+,"host":"playerembedapi\.link"[^}]+\}', content)
            
            for i, match in enumerate(matches):
                if i >= max_requests:
                    break
                    
                try:
                    req = json.loads(match.group())
                    playerembedapi_requests.append(req)
                    
                    # Decodificar raw request
                    if 'raw' in req:
                        decoded = decode_base64(req['raw'])
                        
                        # Extrair URLs de v√≠deo
                        urls = extract_video_urls(decoded)
                        video_urls.update(urls)
                        
                        # Mostrar info da requisi√ß√£o
                        print(f"üì¶ Request #{req['id']}")
                        print(f"   Method: {req['method']} {req['path']}")
                        print(f"   Length: {req['length']} bytes")
                        
                        if urls:
                            print(f"   üéØ URLs encontradas: {len(urls)}")
                            for url in urls:
                                print(f"      - {url[:100]}...")
                        print()
                        
                except Exception as e:
                    continue
                    
        except Exception as e:
            print(f"‚ùå Erro ao parsear JSON: {e}")
    
    # Resumo
    print("=" * 80)
    print("üìä RESUMO DA AN√ÅLISE")
    print("=" * 80)
    print(f"Total de requisi√ß√µes PlayerEmbedAPI analisadas: {len(playerembedapi_requests)}")
    print(f"Total de URLs de v√≠deo encontradas: {len(video_urls)}")
    print()
    
    if video_urls:
        print("üéØ URLs DE V√çDEO ENCONTRADAS:")
        print()
        for url in sorted(video_urls):
            print(f"  {url}")
            print()
    else:
        print("‚ö†Ô∏è  Nenhuma URL de v√≠deo encontrada nas requisi√ß√µes analisadas")
        print()
        print("üí° Poss√≠veis motivos:")
        print("   1. V√≠deos carregados via JavaScript (n√£o aparecem em HTTP)")
        print("   2. URLs encriptadas/ofuscadas")
        print("   3. Requisi√ß√µes de v√≠deo n√£o capturadas pelo Burp")
        print("   4. Arquivo JSON incompleto ou corrompido")

if __name__ == "__main__":
    file_path = r"C:\Users\KYTHOURS\Desktop\logsburpsuit\2026-01-18-162104_json_requests.json"
    analyze_burp_json(file_path, max_requests=50)
