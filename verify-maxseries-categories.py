#!/usr/bin/env python3
"""
Verifica se as categorias do MaxSeries estÃ£o corretas
"""

import requests
from bs4 import BeautifulSoup

def check_url(url, name):
    """Verifica se uma URL estÃ¡ acessÃ­vel e retorna informaÃ§Ãµes"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:146.0) Gecko/20100101 Firefox/146.0'
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Contar items
            items = soup.select('article.item')
            
            # Verificar tÃ­tulo da pÃ¡gina
            page_title = soup.select_one('h1, .page-title, title')
            title_text = page_title.text.strip() if page_title else "N/A"
            
            return {
                'status': 'âœ… OK',
                'code': response.status_code,
                'items': len(items),
                'title': title_text[:50]
            }
        else:
            return {
                'status': 'âš ï¸ ERRO',
                'code': response.status_code,
                'items': 0,
                'title': 'N/A'
            }
    except Exception as e:
        return {
            'status': 'âŒ FALHA',
            'code': 'N/A',
            'items': 0,
            'title': str(e)[:50]
        }

def main():
    print("ğŸ” VERIFICAÃ‡ÃƒO DE CATEGORIAS DO MAXSERIES")
    print("="*80)
    
    base_url = "https://www.maxseries.pics"
    
    categories = [
        (f"{base_url}/", "InÃ­cio"),
        (f"{base_url}/filmes", "Filmes"),
        (f"{base_url}/series", "SÃ©ries"),
        (f"{base_url}/generos/acao", "AÃ§Ã£o"),
        (f"{base_url}/generos/comedia", "ComÃ©dia"),
        (f"{base_url}/generos/drama", "Drama"),
        (f"{base_url}/generos/terror", "Terror"),
        (f"{base_url}/generos/romance", "Romance"),
        (f"{base_url}/generos/animacao", "AnimaÃ§Ã£o"),
    ]
    
    print(f"\nğŸ“ Base URL: {base_url}\n")
    
    results = []
    
    for url, name in categories:
        print(f"ğŸ” Testando: {name:15} â†’ {url}")
        result = check_url(url, name)
        results.append((name, url, result))
        
        print(f"   {result['status']} | HTTP {result['code']} | {result['items']} items | {result['title']}")
        print()
    
    # Resumo
    print("="*80)
    print("ğŸ“Š RESUMO")
    print("="*80)
    
    ok_count = sum(1 for _, _, r in results if r['status'] == 'âœ… OK')
    error_count = sum(1 for _, _, r in results if r['status'] != 'âœ… OK')
    
    print(f"\nâœ… Funcionando: {ok_count}/{len(results)}")
    print(f"âŒ Com erro: {error_count}/{len(results)}")
    
    if error_count > 0:
        print("\nâš ï¸ URLs COM PROBLEMA:")
        for name, url, result in results:
            if result['status'] != 'âœ… OK':
                print(f"  - {name}: {url}")
                print(f"    Erro: {result['title']}")
    
    # SugestÃµes de categorias reais
    print("\n" + "="*80)
    print("ğŸ” DESCOBRINDO CATEGORIAS REAIS DO SITE...")
    print("="*80)
    
    try:
        response = requests.get(base_url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:146.0) Gecko/20100101 Firefox/146.0'
        }, timeout=10)
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Procurar links de menu/navegaÃ§Ã£o
        nav_links = soup.select('nav a, .menu a, header a, .navigation a')
        
        print("\nğŸ“‹ Links encontrados no menu:")
        found_categories = set()
        
        for link in nav_links:
            href = link.get('href', '')
            text = link.text.strip()
            
            if href and text and len(text) > 2:
                # Filtrar apenas links relevantes
                if any(x in href.lower() for x in ['filme', 'serie', 'genero', 'categoria', 'lancamento']):
                    if href.startswith('/'):
                        href = base_url + href
                    
                    if href not in found_categories:
                        found_categories.add(href)
                        print(f"  â€¢ {text:20} â†’ {href}")
        
        # Procurar gÃªneros especÃ­ficos
        print("\nğŸ­ GÃªneros encontrados:")
        genre_links = soup.select('a[href*="genero"], a[href*="genre"], .genres a, .genre a')
        
        for link in genre_links:
            href = link.get('href', '')
            text = link.text.strip()
            
            if href and text:
                if href.startswith('/'):
                    href = base_url + href
                print(f"  â€¢ {text:20} â†’ {href}")
        
    except Exception as e:
        print(f"âŒ Erro ao descobrir categorias: {e}")

if __name__ == "__main__":
    main()
